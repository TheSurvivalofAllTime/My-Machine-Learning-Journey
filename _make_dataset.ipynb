{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28426e3f",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f0f8ff; padding:15px; border-radius:8px; font-size:16px; line-height:1.6;\">\n",
    "\n",
    "  <h3 style=\"margin-top:0;\">Author: Nikolin Prenga</h3>\n",
    "\n",
    "  <p><strong>Summary:</strong></p>\n",
    "\n",
    "  <p>\n",
    "    This notebook organizes and prepares the full dataset for training <strong>YOLO</strong>.\n",
    "    It includes three main steps:\n",
    "  </p>\n",
    "\n",
    "  <ol>\n",
    "    <li>\n",
    "      Generating YOLO-format annotations from binary tumor masks and no-tumor images using bounding boxes \n",
    "      with normalized coordinates: <code>x_center, y_center, width, height</code>.\n",
    "    </li>\n",
    "    <li>\n",
    "      Splitting the full dataset into training and validation sets (default 80/20), \n",
    "      while keeping all four categories: <em>glioma</em>, <em>meningioma</em>, <em>pituitary</em>, and <em>no tumor</em>.\n",
    "    </li>\n",
    "    <li>\n",
    "      Moving the test dataset from <code>Data_organize_Nikolin</code> into the final structure \n",
    "      <code>Yolo_v11_Nikolin_Dataset</code>, including images, masks, and YOLO label files.\n",
    "    </li>\n",
    "    </li>\n",
    "  </ol>\n",
    "\n",
    "  <p>\n",
    "    The resulting dataset structure is suitable for training and evaluating both <strong>YOLOv11</strong> and <strong>YOLOv12</strong>.\n",
    "  </p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59909fc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "133e4296",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os   \n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import yaml\n",
    "from ultralytics import YOLO\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b50d772a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to delete files in a directory\n",
    "\n",
    "def delete_one_file(directory):\n",
    "    for filename in os.listdir(directory):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)\n",
    "            print(f\"Deleted: {file_path}\")\n",
    "            #break  # Delete only one file\n",
    "\n",
    "#delete_one_file('Yolo_v11_Nikolin_Dataset/val/images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b3c92d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec0b9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The purpose of this function copy_files_only is to create a new dataset by copying\n",
    "# images and masks from the brisc2025 dataset to my folder Data_organize_Nikolin under train and test, \n",
    "# each with a subdirectory: images and masks.\n",
    "# This function copies images and masks from the original directory to a target one we're organizing.\n",
    "# It removes unnecessary parts of the filename, keeping only the ID and a suffix (e.g., _gL_ for glioma, _me_ for meningioma).\n",
    "# It retains all anatomical planes: Axial, Coronal, and Sagittal, along with their respective suffixes.\n",
    "\n",
    "def copy_files_only(src_folder_image,\n",
    "                    src_folder_mask,\n",
    "                    dest_folder_image, \n",
    "                    dest_folder_mask):\n",
    "    \"\"\"\n",
    "    Copy and rename files from source folders to destination folders,\n",
    "    trimming the filenames to keep only the suffix (e.g., '_00001_gl_ax_t1.jpg').\n",
    "    \"\"\"\n",
    "\n",
    "    for filename in os.listdir(src_folder_image):\n",
    "        src_image_path = os.path.join(src_folder_image, filename)\n",
    "        src_mask_path = os.path.join(src_folder_mask, filename)\n",
    "\n",
    "        if os.path.isfile(src_image_path):\n",
    "            # Shorten the filename by keeping only the suffix\n",
    "            parts = filename.split(\"_\")\n",
    "            if len(parts) >= 4:\n",
    "                new_filename = \"_\" + \"_\".join(parts[-4:])\n",
    "            else:\n",
    "                new_filename = filename  # fallback if format doesn't match\n",
    "\n",
    "            image = cv2.imread(src_image_path, cv2.IMREAD_COLOR)\n",
    "            mask = cv2.imread(src_mask_path, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "            if image is None or mask is None:\n",
    "                print(f'Image or mask is None for {filename}')\n",
    "                continue\n",
    "            destination_image_path = os.path.join(dest_folder_image, new_filename)\n",
    "            destination_mask_path = os.path.join(dest_folder_mask, new_filename)\n",
    "\n",
    "            cv2.imwrite(destination_image_path, image)\n",
    "            cv2.imwrite(destination_mask_path, mask)\n",
    "            print(f\"Copied {filename} as {new_filename}\")\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7ccf14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9175e974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 860)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Define source and destination folders for images and masks in the training set\n",
    "src_folder_image_train= 'brisc2025/segmentation_task/train/images'\n",
    "src_folder_mask_train = 'brisc2025/segmentation_task/train/masks'\n",
    "dest_folder_image_train = 'Data_organize_Nikolin/train/images'\n",
    "dest_folder_mask_train = 'Data_organize_Nikolin/train/masks'\n",
    "\n",
    "# #Copy and rename files from source folders to destination folders\n",
    "# copy_files_only(src_folder_image_train,\n",
    "#                     src_folder_mask_train,\n",
    "#                     dest_folder_image_train, \n",
    "#                     dest_folder_mask_train)\n",
    "\n",
    "# # Define source and destination folders for images and masks in the testining/unseen set\n",
    "\n",
    "src_folder_image_test = 'brisc2025/segmentation_task/test/images'\n",
    "src_folder_mask_test = 'brisc2025/segmentation_task/test/masks'\n",
    "dest_folder_image_test = 'Data_organize_Nikolin/test/images'\n",
    "dest_folder_mask_test = 'Data_organize_Nikolin/test/masks'\n",
    "\n",
    "# # Copy and rename files from source folders to destination folders\n",
    "# copy_files_only(src_folder_image_test,\n",
    "#                     src_folder_mask_test,\n",
    "#                     dest_folder_image_test, \n",
    "#                     dest_folder_mask_test)\n",
    "\n",
    "len(os.listdir(dest_folder_image_test)), len(os.listdir(dest_folder_mask_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952dd39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Above, all images and masks were copied to Data_organize_Nikolin from brisc2025/segmentation\n",
    "# Since no-tumor images are not included there, we copy them from the classification folder\n",
    "# These are moved to their respective 'train' and 'test' folders under 'images' in Data_organize_Nikolin\n",
    "def copy_no_tumor_files(src_folder_image, dest_folder_image):\n",
    "    \"\"\"\n",
    "    Copy no_tumor images from src_folder_image to dest_folder_image,\n",
    "    renaming them to only include the last 4 parts separated by '_'.\n",
    "    \"\"\"\n",
    "\n",
    "    for filename in os.listdir(src_folder_image):\n",
    "        src_image_path = os.path.join(src_folder_image, filename)\n",
    "\n",
    "        if not os.path.isfile(src_image_path):\n",
    "            continue\n",
    "\n",
    "        parts = filename.split(\"_\")\n",
    "        if len(parts) >= 4:\n",
    "            new_filename = \"_\" + \"_\".join(parts[-4:])\n",
    "        else:\n",
    "            new_filename = filename  # fallback\n",
    "\n",
    "        image = cv2.imread(src_image_path, cv2.IMREAD_COLOR)\n",
    "        if image is None:\n",
    "            print(f\"Image is None for {filename}\")\n",
    "            continue\n",
    "\n",
    "        dest_image_path = os.path.join(dest_folder_image, new_filename)\n",
    "        cv2.imwrite(dest_image_path, image)\n",
    "        print(f\"Saved: {dest_image_path}\")\n",
    "\n",
    "\n",
    "# Define source  folders for no_tumor images in training and testing sets \n",
    "src_folder_no_tumor_train = 'brisc2025/classification_task/train/no_tumor'\n",
    "src_folder_no_tumor_test='brisc2025/classification_task/test/no_tumor'\n",
    "\n",
    "# # copy no tumor images from source folder to destination folder in training set\n",
    "# copy_no_tumor_files(src_folder_no_tumor_train, dest_folder_image_train)\n",
    "\n",
    "# # copy no tumor images from source folder to destination folder in testing set\n",
    "#copy_no_tumor_files(src_folder_no_tumor_test, dest_folder_image_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf8fb04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab084f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf245ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function generates bounding boxes from a binary mask created by radiologists or physicians.\n",
    "# It takes a mask as input and returns a list of bounding boxes in (x_min, y_min, width, height) format.\n",
    "# These boxes are suitable for use in annotation tools and object detection models.\n",
    "\n",
    "def mask_to_bboxes(mask, min_area=180):\n",
    "    # Step 1: Ensure single-channel binary mask (0 and 255, uint8)\n",
    "    if mask.ndim == 3:\n",
    "        mask = cv2.cvtColor(mask, cv2.COLOR_RGB2GRAY)\n",
    "    mask_bin = (mask > 0).astype(np.uint8)\n",
    "\n",
    "    # Step 2: Find contours\n",
    "    #contours, _ = cv2.findContours(mask_bin, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours, _ = cv2.findContours(mask_bin, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\n",
    "    # Step 3: Extract and filter bounding boxes\n",
    "    bboxes = []\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        if w * h >= min_area:  # ignore tiny noise\n",
    "            bboxes.append((x, y, w, h))\n",
    "    return bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67c3032",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd9bb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To properly train on \"no tumor\" cases, we need bounding boxes â€” but what should they cover?\n",
    "# We propose generating large bounding boxes that enclose the skull, effectively separating it from the background.\n",
    "def get_skull_bbox(image_path):\n",
    "    \"\"\"\n",
    "    Returns the bounding box (x_min, y_min, width, height) around the skull in an MRI image.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Path to the input image.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (x_min, y_min, width, height)\n",
    "    \"\"\"\n",
    "    image = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    _, thresh = cv2.threshold(gray, 80, 255, cv2.THRESH_BINARY)\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    cleaned = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    contours, _ = cv2.findContours(cleaned, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if not contours:\n",
    "        return None  # No contour found\n",
    "\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "    x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "\n",
    "    return x, y, w, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24df30ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa15d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function generates YOLO-format labels from image-mask pairs.\n",
    "# For \"no tumor\" cases, it uses a skull-based bounding box.\n",
    "# For tumor cases, it uses the mask to generate bounding boxes via mask_to_bboxes().\n",
    "# Class labels are assigned based on filename suffix: 0 = glioma, 1 = meningioma, 2 = pituitary, 3 = no tumor.\n",
    "# Each object is represented in YOLO format as: \n",
    "# class_id, x_center_normalized, y_center_normalized, width_normalized, height_normalized\n",
    "\n",
    "\n",
    "def make_anotations_from_masks(image_source, mask_source, annotations_path, mask_to_bboxes):\n",
    "\n",
    "    pass\n",
    "    \"\"\"    Create annotations from masks in the specified source directories and save them in the specified annotations path.   \n",
    "    Args:\n",
    "        image_source (str): Path to the source directory containing images.\n",
    "        mask_source (str): Path to the source directory containing masks.\n",
    "        annotations_path (str): Path to the directory where annotations will be saved.\n",
    "        mask_to_bboxes (function): Function to convert masks to bounding boxes.\n",
    "    \"\"\"\n",
    "    for image_name in os.listdir(image_source):\n",
    "        if not image_name.endswith(('.jpg', '.png')):\n",
    "            continue\n",
    "\n",
    "        # if '_no_' in image_name:\n",
    "        #     label_name = os.path.splitext(image_name)[0] + '.txt'\n",
    "\n",
    "        #     with open(os.path.join(annotations_path, label_name), 'w') as f:\n",
    "        #         f.write(f'{0} {0} {0} {0} {0}\\n')\n",
    "        #     continue\n",
    "\n",
    "        if '_no_' in image_name:\n",
    "            im_no_tumor = cv2.imread(os.path.join(image_source, image_name))\n",
    "            if im_no_tumor is None:\n",
    "                print(f\"Image not found for {image_name}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            bbox_no_tumor = get_skull_bbox(os.path.join(image_source, image_name))\n",
    "            if bbox_no_tumor is None:\n",
    "                print(f\"No bounding box found for {image_name}. Skipping.\")\n",
    "                continue\n",
    "            x_min, y_min, width, height = bbox_no_tumor\n",
    "            # determine x_center, y_center, width_normalized, height_normalized\n",
    "            width_image, height_image = im_no_tumor.shape[1], im_no_tumor.shape[0]\n",
    "            x_center = x_min + width / 2\n",
    "            y_center = y_min + height / 2\n",
    "            x_center_normalized = x_center / width_image\n",
    "            y_center_normalized = y_center / height_image\n",
    "            width_normalized = width / width_image\n",
    "            height_normalized = height / height_image   \n",
    "            \n",
    "            \n",
    "            label_name = os.path.splitext(image_name)[0] + '.txt'\n",
    "\n",
    "            with open(os.path.join(annotations_path, label_name), 'w') as f:\n",
    "                f.write(f'{3} {x_center_normalized} {y_center_normalized} {width_normalized} {height_normalized}\\n')\n",
    "\n",
    "            continue\n",
    "\n",
    "\n",
    "\n",
    "        # Assign class based on image name\n",
    "        if '_gl_' in image_name:\n",
    "            class_name = 0\n",
    "        elif '_me_' in image_name:\n",
    "            class_name = 1\n",
    "        elif '_pi_' in image_name:\n",
    "            class_name = 2\n",
    "        else:\n",
    "            print(f\"Unknown class in {image_name}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Read the corresponding mask\n",
    "        mask_path= os.path.join(mask_source, image_name)\n",
    "\n",
    "        mask = cv2.imread(mask_path)\n",
    "        if mask is None:\n",
    "            print(f\"Mask not found for {image_name}. Skipping.\")\n",
    "            continue\n",
    "        image = cv2.imread(os.path.join(image_source, image_name))\n",
    "        if image is None:\n",
    "            print(f\"Image not found for {image_name}. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        width_image, height_image = image.shape[1], image.shape[0]\n",
    "\n",
    "        if image.shape[:2] != mask.shape[:2]:\n",
    "            print(f\"Image and mask dimensions do not match for {image_name}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "\n",
    "        # Convert mask to bounding boxes\n",
    "        bboxes = mask_to_bboxes(mask)\n",
    "        if not bboxes:\n",
    "            print(f\"No bounding boxes found for {image_name}. Skipping.\")\n",
    "            continue\n",
    "        # Create annotation file\n",
    "\n",
    "        #annotation_file = os.path.join(annotations_path, image_name.replace('.jpg', '.txt'))\n",
    "\n",
    "        base_name = os.path.splitext(image_name)[0]\n",
    "        annotation_file = os.path.join(annotations_path, base_name + \".txt\")\n",
    "\n",
    "\n",
    "        with open(annotation_file, 'w') as f:\n",
    "            for (x_min, y_min, width, height) in bboxes:\n",
    "                x_center = (x_min + width / 2) \n",
    "                y_center = (y_min + height / 2)\n",
    "                x_center_normalized = x_center / width_image\n",
    "                y_center_normalized = y_center / height_image\n",
    "                width_normalized = width / width_image\n",
    "                height_normalized = height / height_image\n",
    "                f.write(f'{class_name} {x_center_normalized} {y_center_normalized} {width_normalized} {height_normalized}\\n')\n",
    "\n",
    "                print(f'{x_min} {y_min} {x_center} {y_center} {width} {height}\\n')\n",
    "\n",
    "                print(f'image name: {image_name}  \\n   ')\n",
    "            \n",
    "            \n",
    "# Define source and destination folders for images and masks in the training set\n",
    "\n",
    "\n",
    "image_source_train ='Data_organize_Nikolin/train/images'\n",
    "mask_source_train ='Data_organize_Nikolin/train/masks'\n",
    "annotations_path_train = 'Data_organize_Nikolin/train/labels'\n",
    "\n",
    "#make_anotations_from_masks(image_source_train, mask_source_train, annotations_path_train, mask_to_bboxes)\n",
    "\n",
    "image_source_test = 'Data_organize_Nikolin/test/images'\n",
    "mask_source_test = 'Data_organize_Nikolin/test/masks'\n",
    "annotations_path_test = 'Data_organize_Nikolin/test/labels'\n",
    "\n",
    "#make_anotations_from_masks(image_source_test, mask_source_test, annotations_path_test, mask_to_bboxes)\n",
    "\n",
    "#print(len(os.listdir(annotations_path_train)), len(os.listdir(annotations_path_test))   )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb37e377",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b66697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function splits a large training dataset into two parts: training and validation.\n",
    "# The dataset contains four categories: glioma, meningioma, pituitary tumor, and no tumor.\n",
    "# Each image is categorized based on its filename suffix: '_gl_', '_me_', '_pi_', '_no_'.\n",
    "# A fixed percentage (default 20%) of images is randomly selected from each category to form the validation set.\n",
    "# The remaining 80% per category is used as the updated training set.\n",
    "#\n",
    "# All selected images and their corresponding label files are copied into two newly created directories:\n",
    "# - Yolo_v11_Nikolin_Dataset/train/images and /train/labels\n",
    "# - Yolo_v11_Nikolin_Dataset/val/images and /val/labels\n",
    "#\n",
    "# This ensures the resulting dataset is structured for YOLO training with clean separation between training and validation.\n",
    "\n",
    "#\n",
    "def _make_val_dataset(main_train_folder_images, \n",
    "                      main_train_folder_labels,\n",
    "                      train_new_folder_images,\n",
    "                        train_new_folder_labels,\n",
    "                        val_new_folder_images,\n",
    "                        val_new_folder_labels,\n",
    "                          val_ratio=0.20):\n",
    "    \n",
    "    main_folder_images = os.listdir(main_train_folder_images)\n",
    "\n",
    "\n",
    "    \n",
    "    glioma_images = np.array([img for img in main_folder_images if '_gl_' in img])\n",
    "    meningioma_images = np.array([img for img in main_folder_images if '_me_' in img])\n",
    "    pituitary_images = np.array([img for img in main_folder_images if '_pi_' in img])\n",
    "    no_tumor_images = np.array([img for img in main_folder_images if '_no_' in img])\n",
    "    print(f'{len(glioma_images)+ len(meningioma_images) + len(pituitary_images) + len(no_tumor_images)} total images in the training set   ') \n",
    "    print(f'{len(glioma_images)} glioma images, {len(meningioma_images)} meningioma images, {len(pituitary_images)} pituitary images, {len(no_tumor_images)} no_tumor images')\n",
    "\n",
    "\n",
    "    \n",
    "    # Shuffle the images in each category and split them into training and validation sets\n",
    "    selected_glioma_val = np.random.choice(glioma_images, size=int(len(glioma_images)*val_ratio), replace=False)\n",
    "    selected_meningioma_val = np.random.choice(meningioma_images, size=int(len(meningioma_images)*val_ratio), replace=False)\n",
    "    selected_pituitary_val = np.random.choice(pituitary_images, size=int(len(pituitary_images)*val_ratio), replace=False)\n",
    "    selected_no_tumor_val = np.random.choice(no_tumor_images, size=int(len(no_tumor_images)*val_ratio), replace=False) \n",
    "    print(f'{len(selected_glioma_val)} glioma validation images, {len(selected_meningioma_val)} meningioma validation images, {len(selected_pituitary_val)} pituitary validation images, {len(selected_no_tumor_val)} no_tumor validation images')\n",
    "\n",
    "    # Create the validation set by combining the selected images\n",
    "\n",
    "    images_val = np.concatenate((selected_glioma_val, selected_meningioma_val, selected_pituitary_val, selected_no_tumor_val))\n",
    "\n",
    "    np.random.shuffle(images_val)\n",
    "    print(f'{len(images_val)} total images in the validation set     ')\n",
    "\n",
    "    # Remaining 80% for training\n",
    "    remaining_glioma = np.setdiff1d(glioma_images, selected_glioma_val)\n",
    "    remaining_meningioma = np.setdiff1d(meningioma_images, selected_meningioma_val)\n",
    "    remaining_pituitary = np.setdiff1d(pituitary_images, selected_pituitary_val)\n",
    "    remaining_no_tumor = np.setdiff1d(no_tumor_images, selected_no_tumor_val)\n",
    "    print(f'{len(remaining_glioma)+ len(remaining_meningioma) + len(remaining_pituitary) + len(remaining_no_tumor)} total images in the training set after validation split ')\n",
    "\n",
    "    \n",
    "    \n",
    "    # Create the training set by combining the remaining images\n",
    "    images_train = np.concatenate((remaining_glioma, remaining_meningioma, remaining_pituitary, remaining_no_tumor))\n",
    "    np.random.shuffle(images_train)\n",
    "    print(f'{len(images_train)} total images in the training set after validation split ')\n",
    "\n",
    "        \n",
    "\n",
    "    # Copy training images and labels to the new folder\n",
    "\n",
    "    for image_val in images_val:\n",
    "        image_source_val = os.path.join(main_train_folder_images, image_val)\n",
    "\n",
    "        if os.path.isfile(image_source_val):\n",
    "            image_val_test = os.path.join(val_new_folder_images, image_val)\n",
    "\n",
    "            shutil.copy(image_source_val, image_val_test )\n",
    "\n",
    "            # Copy corresponding label file\n",
    "\n",
    "            label_file = image_val.replace('.jpg', '.txt').replace('.png', '.txt')\n",
    "\n",
    "            label_from_source = os.path.join(main_train_folder_labels, label_file)\n",
    "\n",
    "            \n",
    "            if os.path.isfile(label_from_source):\n",
    "                label_destination = os.path.join(val_new_folder_labels, label_file )\n",
    "                shutil.copy(label_from_source, label_destination )\n",
    "\n",
    "            else:\n",
    "                print(f\"Label file not found for {image_val}. Skipping label copy.\")\n",
    "\n",
    "    # Copy training images and labels to the new folder\n",
    "\n",
    "    for image_train in images_train:\n",
    "        source_path_main_train = os.path.join(main_train_folder_images, image_train )\n",
    "\n",
    "        if os.path.isfile(source_path_main_train):\n",
    "            destination_train_images = os.path.join(train_new_folder_images, image_train)\n",
    "\n",
    "            shutil.copy(source_path_main_train, destination_train_images)\n",
    "\n",
    "            # Copy corresponding label file\n",
    "            label_file_train = image_train.replace('.jpg', '.txt').replace('.png', '.txt')\n",
    "            \n",
    "            source_label_path_train = os.path.join(main_train_folder_labels, label_file_train)\n",
    "            \n",
    "            if os.path.isfile(source_label_path_train):\n",
    "                destination_label_path_train = os.path.join(train_new_folder_labels, label_file_train)\n",
    "                shutil.copy(source_label_path_train, destination_label_path_train)\n",
    "            else:\n",
    "                print(f\"Label file not found for {image_train}. Skipping label copy.\")\n",
    "\n",
    "\n",
    "main_train_folder_images= 'Data_organize_Nikolin/train/images'\n",
    "main_train_folder_labels = 'Data_organize_Nikolin/train/labels'\n",
    "train_new_folder_images ='Yolo_v11_Nikolin_Dataset/train/images'\n",
    "train_new_folder_labels ='Yolo_v11_Nikolin_Dataset/train/labels'\n",
    "val_new_folder_images ='Yolo_v11_Nikolin_Dataset/val/images'\n",
    "val_new_folder_labels ='Yolo_v11_Nikolin_Dataset/val/labels'\n",
    "\n",
    "# _make_val_dataset(main_train_folder_images,\n",
    "#                       main_train_folder_labels,\n",
    "#                       train_new_folder_images,\n",
    "#                         train_new_folder_labels,\n",
    "#                         val_new_folder_images,\n",
    "#                         val_new_folder_labels,\n",
    "#                         val_ratio=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ec4c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this function just_copy_from_one_directory_to_another, we aim to copy files from one directory to another.\n",
    "# In the Data_organize_Nikolin folder, we want to move all the testing dataset into Yolo_v11_Nikolin_Dataset.\n",
    "# This Yolo_v11_Nikolin_Dataset will be chosen as the final dataset for training YOLOv11 and YOLOv12 and for performing inference.\n",
    "\n",
    "def just_copy_from_one_directory_to_another(source_directory, destination_directory):\n",
    "    os.makedirs(destination_directory, exist_ok=True)\n",
    "\n",
    "    files_from_source = os.listdir(source_directory)\n",
    "\n",
    "    for file in files_from_source:\n",
    "        file_from_source = os.path.join(source_directory, file)\n",
    "\n",
    "        if os.path.isfile(file_from_source):  \n",
    "            file_to_destination = os.path.join(destination_directory, file)\n",
    "            shutil.copy(file_from_source, file_to_destination)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb08850",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_directory_images = 'Data_organize_Nikolin/test/images'\n",
    "destination_directory_images = 'Yolo_v11_Nikolin_Dataset/test/images'\n",
    "#just_copy_from_one_directory_to_another(source_directory_images,destination_directory_images )\n",
    "\n",
    "source_directory_masks_test = 'Data_organize_Nikolin/test/masks'\n",
    "destination_directory_mask_test = 'Yolo_v11_Nikolin_Dataset/test/masks'\n",
    "#just_copy_from_one_directory_to_another(source_directory_masks_test,destination_directory_mask_test )\n",
    "\n",
    "source_directory_labels_test ='Data_organize_Nikolin/test/labels'\n",
    "destination_directory_labels_test = 'Yolo_v11_Nikolin_Dataset/test/labels'\n",
    "#just_copy_from_one_directory_to_another(source_directory_labels_test, destination_directory_labels_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792fe1ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c8ef63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Nikolin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
